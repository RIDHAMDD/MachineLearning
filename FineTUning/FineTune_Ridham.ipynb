{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be94e6d6-4096-4d1a-aa58-5afd89f33bff",
   "metadata": {},
   "source": [
    "# Ridham Dholaria - Final Project\n",
    "\n",
    "# Fine-tuning \n",
    "\n",
    "### Definition:\n",
    "Fine tuning is taking a pre-trained existing large language model and training at least one internal model parameter for a particular use case. \n",
    "\n",
    "### Description: \n",
    "Here I am taking the [IMDB](https://huggingface.co/datasets/imdb) (Large Movie Review Dataset containing movie reviews labeled as positive or negative) dataset and getting the randomly 20% of the data to work with as it will become computationally difficult if I run the entire dataset.\n",
    "Then I build the model using [FacebookAI/roberta-base](https://huggingface.co/FacebookAI/roberta-base) model. Which is a pre-trained model of the English language using a masked language modeling (MLM) objective. Then comes the preprocess where I Tokenize the data using [AutoTokenizer](https://huggingface.co/docs/transformers/main_classes/tokenizer). It is necessary to convert the text to numerical form for model comprehension.\n",
    "\n",
    "\n",
    "Citation link: https://github.com/ShawhinT/YouTube-Blog/blob/main/LLMs/fine-tuning/ft-example.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b69f5cb-eb89-44d3-9c9e-4d67bdce80f0",
   "metadata": {},
   "source": [
    "Due to limitations in GPU memory and computational resources, I downscaled the original IMDB dataset from 25,000 entries to 1000 entries (4% of the original data) for training. Despite trying to increase the number of epochs beyond 10, CUDA ran out of memory. Therefore, I proceeded with the available parameters. However, the achieved accuracy is around 55%, which might not be optimal. Given more GPU resources, training with higher parameters could potentially yield better results. Considering the constraints, I am considering submitting the model with 50% accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919f28c7-f4f7-42e4-954c-3ab0e248e199",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864a8967-255a-401f-b374-343ef8bdeed9",
   "metadata": {},
   "source": [
    "Importing various libraries and modules for natural language processing (NLP) such as datasets, [peft](https://huggingface.co/docs/peft/en/index), [evaluate](https://huggingface.co/docs/evaluate/en/index), [torch](https://pytorch.org/docs/stable/torch.html) and [numpy](https://numpy.org/doc/stable/user/index.html#user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ef8ea85-d04d-4217-99a3-21c446bf2ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoConfig, \n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer)\n",
    "\n",
    "from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\n",
    "import evaluate\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6a4484-07d8-49dd-81ef-672105f53ebe",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa9722d3-0609-4aea-9585-9aa2cfc1fc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading imdb data\n",
    "imdb_dataset = load_dataset(\"imdb\")\n",
    "\n",
    "# defining subsample size\n",
    "N = 20000 \n",
    "# generating indexes for random subsample\n",
    "rand_idx = np.random.randint(24999, size=N) \n",
    "\n",
    "# extracting train and test data\n",
    "x_train = imdb_dataset['train'][rand_idx]['text']\n",
    "y_train = imdb_dataset['train'][rand_idx]['label']\n",
    "\n",
    "x_test = imdb_dataset['test'][rand_idx]['text']\n",
    "y_test = imdb_dataset['test'][rand_idx]['label']\n",
    "\n",
    "# creating new dataset\n",
    "dataset = DatasetDict({'train':Dataset.from_dict({'label':y_train,'text':x_train}),\n",
    "                             'validation':Dataset.from_dict({'label':y_test,'text':x_test})})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a21663a-9357-4f23-9a52-4225b5b00a54",
   "metadata": {},
   "source": [
    "loading the IMDb dataset and creating a subsample of 5000 data points for both the training and testing sets. It then splits the data into training and validation sets and organizes them into a new dataset for further processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3644c68d-9adf-48a4-90a2-8fd89555a302",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521d9791-f1ca-4dae-8629-f19ab4771f45",
   "metadata": {},
   "source": [
    "Used [FacebookAI/roberta-base](https://huggingface.co/FacebookAI/roberta-base)model for the assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b746f74b-7aaa-435b-8253-97f324a8cb53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "id2label = {0: \"Negative\", 1: \"Positive\"}\n",
    "label2id = {\"Negative\":0, \"Positive\":1}\n",
    "\n",
    "# generate classification model from model_checkpoint\n",
    "model = AutoModelForSequenceClassification.from_pretrained('roberta-base', num_labels=2, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a28896-b967-427c-baeb-ca6ae442473b",
   "metadata": {},
   "source": [
    "Initializes a classification model using the [roberta-base](https://huggingface.co/FacebookAI/roberta-base) architecture for binary sentiment classification (negative or positive). It specifies mappings between label IDs and their corresponding labels (\"Negative\" and \"Positive\") for model interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "853002f8-d39c-4bc4-8d07-e44a47de3b47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display architecture\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc98609-873d-455c-bac4-155632cda484",
   "metadata": {},
   "source": [
    "### Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7fe08707-657f-4e66-aa72-84899c54bf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base', add_prefix_space=True)\n",
    "\n",
    "# add pad token if none exists\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ad6f72-8dfe-40fb-b48d-98650b489ebb",
   "metadata": {},
   "source": [
    "Initializes a tokenizer using the Hugging Face library, ensuring it adds a space before each token. If the tokenizer lacks a padding token, it adds one, [PAD], and adjusts the model's token embeddings accordingly. This ensures consistent tokenization and padding across different model configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20f4adb9-ce8f-4f54-9b94-300c9daae1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tokenize function\n",
    "def tokenize_function(examples):\n",
    "    # extract text\n",
    "    text = examples[\"text\"]\n",
    "\n",
    "    #tokenize and truncate text\n",
    "    tokenizer.truncation_side = \"left\"\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"np\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa2838f-2ac4-4381-82c3-8d6e26e18fb5",
   "metadata": {},
   "source": [
    "Function takes examples containing text data as input. It tokenizes the text, truncating it from the left side if needed to fit within a maximum length of 512 tokens, and returns the tokenized inputs as numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7600bcd-7e93-4fb4-bd8d-ffc76bed1ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebba32a9ba9746bfb10233af6c00039c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd04d7792965490a987023979f936df1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 20000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 20000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize training and validation datasets\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f8e85f9-1804-4f49-a783-4da59580ea1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb12492-1ef5-4287-86eb-6a4d170f9afb",
   "metadata": {},
   "source": [
    "Initializes a data collator, which is used to pad sequences to the maximum length within a batch during training. It utilizes the tokenizer previously defined."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd9a120-580d-470c-a981-7c7e22604865",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a894819-2e9c-4a53-9790-32130c182bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import accuracy evaluation metric\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c07b9be2-a3f6-4b38-b9e8-6a2bc8aa945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an evaluation function to pass into trainer later\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    return {\"accuracy\": accuracy.compute(predictions=predictions, references=labels)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d497567-578a-4509-ba9a-3ac44f436a13",
   "metadata": {},
   "source": [
    "Imports the accuracy evaluation metric and defines a function, compute_metrics, which computes the accuracy metric for model predictions. It compares the predicted labels with the actual labels and returns the accuracy value. This function will be passed into the trainer later for evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff356f78-c9fd-4f2b-8f5b-097cf29c1c08",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4dde538-cd7f-4ab5-a96d-c30f3003822e",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(task_type=\"SEQ_CLS\",\n",
    "                        r=4,\n",
    "                        lora_alpha=32,\n",
    "                        lora_dropout=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e499cd19-d529-4f2a-9b8f-1281bdb8ab4b",
   "metadata": {},
   "source": [
    "This code initializes a configuration object for the Lora model, specifying hyperparameters such as task type (sequence classification), attention radius (r=4), Lora's alpha value (lora_alpha=32), and dropout rate (lora_dropout=0.01)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e0d9408-9fc4-4bd3-8d35-4d8217fe01e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 739,586 || all params: 125,386,756 || trainable%: 0.5898437949858117\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5db78059-e5ae-4807-89db-b58ef6abedd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "lr = 0.001\n",
    "batch_size = 2\n",
    "num_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9244ed55-65a4-4c66-8388-55efd87bceb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir= 'roberta-base' + \"-lora-text-classification-output\",\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f5bdc1-1dea-4f9c-818c-216d762f0058",
   "metadata": {},
   "source": [
    "Defines training arguments for the model training process. It specifies parameters such as the output directory for saving the trained model, learning rate, batch size for training and evaluation, number of epochs for training, weight decay, evaluation strategy (per epoch), strategy for saving models (per epoch), and whether to load the best model at the end of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81029270-2cb6-4b63-a09c-737cf3b25446",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8b72d62-fdf1-42c9-9031-790360bb0cd0",
   "metadata": {},
   "source": [
    "The code below creates a trainer object for training the model. It utilizes the defined model, training arguments, tokenized training and evaluation datasets, tokenizer, data collator (for padding examples in each batch), and a function for computing evaluation metrics. Then, it initiates the training process by calling the train() method on the trainer object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dbc1398f-f119-4da0-800c-eb5b8173a4b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30000' max='30000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30000/30000 2:54:12, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.821400</td>\n",
       "      <td>0.723342</td>\n",
       "      <td>{'accuracy': 0.4979}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.769200</td>\n",
       "      <td>0.732342</td>\n",
       "      <td>{'accuracy': 0.5021}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.700400</td>\n",
       "      <td>0.693324</td>\n",
       "      <td>{'accuracy': 0.5021}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=30000, training_loss=0.7908513966878256, metrics={'train_runtime': 10453.1466, 'train_samples_per_second': 5.74, 'train_steps_per_second': 2.87, 'total_flos': 1.0728339444312432e+16, 'train_loss': 0.7908513966878256, 'epoch': 3.0})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creater trainer object\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator, # This will dynamically pad examples in each batch to be equal length\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# train model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235c7184-aa19-4111-b5a2-3bf574fb1987",
   "metadata": {},
   "source": [
    "### Accuracy: 50.21%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23461df0-6e21-4977-9bc8-4313c33cff25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b81e9127-2757-4e83-a902-dc9482bc449c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22500' max='22500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22500/22500 2:06:28, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.767400</td>\n",
       "      <td>0.811388</td>\n",
       "      <td>{'accuracy': 0.5054666666666666}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.731200</td>\n",
       "      <td>0.719436</td>\n",
       "      <td>{'accuracy': 0.4945333333333333}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.702773</td>\n",
       "      <td>{'accuracy': 0.5054666666666666}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=22500, training_loss=0.7535486938476562, metrics={'train_runtime': 7588.9126, 'train_samples_per_second': 5.93, 'train_steps_per_second': 2.965, 'total_flos': 8080859342571024.0, 'train_loss': 0.7535486938476562, 'epoch': 3.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creater trainer object\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator, # This will dynamically pad examples in each batch to be equal length\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# train model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03264afa-7211-4350-b6de-eeac7222ebbc",
   "metadata": {},
   "source": [
    "### Accuracy: 50.54%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cf2a43-f29e-41b1-8821-4df9c5e85c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f5664d1-9bd2-4ce1-bc24-cab5adf80f49",
   "metadata": {},
   "source": [
    "### Generate prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78408dbb-6c09-45ad-af45-8ce3c57d9a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = [\"It was good.\", \"Not a fan, don't recommed.\", \"Better than the first one.\", \"This is not worth watching even once.\", \"This one is a pass.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5dc029e-1c16-491d-a3f1-715f9e0adf52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model predictions:\n",
      "--------------------------\n",
      "It was good. - Positive\n",
      "Not a fan, don't recommed. - Positive\n",
      "Better than the first one. - Positive\n",
      "This is not worth watching even once. - Positive\n",
      "This one is a pass. - Positive\n"
     ]
    }
   ],
   "source": [
    "model.to('cuda') \n",
    "\n",
    "print(\"Trained model predictions:\")\n",
    "print(\"--------------------------\")\n",
    "for text in text_list:\n",
    "    inputs = tokenizer.encode(text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    logits = model(inputs).logits\n",
    "    predictions = torch.max(logits,1).indices\n",
    "\n",
    "    print(text + \" - \" + id2label[predictions.tolist()[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5877ed21-d230-418e-ae16-1ca068f480e2",
   "metadata": {},
   "source": [
    "This code transfers the model to the GPU for faster computation. Then, it iterates through a list of texts, encodes each text using the tokenizer, and passes the encoded inputs to the model for prediction. Finally, it prints the predicted label for each text based on the maximum logit score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e842c3d9-0d80-47b5-aa8b-66e8d0ca6e22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
